# Transfer Learning

### 필요성

고해상도의 칼라이미지의 경우 CNN이 제대로 인식하기 위해서는 5개의 conv 층과 2개의 fully connected 층이 필요하다. 이는 1개의 CPU환경에서 실행시 (일반 컴퓨터)  수백에서 수천시간이 소요가 된다. 

CNN구조를 다시 만들고 하이퍼 파라미터를 조정하는 과정까지 포함한다면 너무나 많은 시간이 소요되기 때문에 아주 치명적인 단점이라고 할 수 있다. 

그렇다면 만약 미리 사전에 훈련된 모델이 존재하고, 이미 학습된 모델에 우리가 분석하고자 하는 이미지에 맞도록 다양한 하이퍼 파라미터를 수정하여 빠르게 사용할 수 있다면 문제가 해결되지 않을까?

**임의의 값으로 초기화된 파라미터를 처음부터 학습시키는 것 보다 소요시간을 획기적으로 줄일 수 있다면 짧은 시간안데 데이터 학습이 가능할 것이란 것이다.**

이처럼 이미 존재하는 뛰어난 성능의 훈련된 구조를 기반으로 내가 가진 데이터에 맞추는 작업 (fine tuning) 으로 작은 변화만 주어 학습시키는 방법을 Transfer learning이라고 한다.

> Resnet 과 Inception 모델이 거의 사용된다.

### 동작방법

○와 △ 모양에 잘 훈련된 모델을 가져와서, 새로운 데이터인 □의 특징을 뽑아 이에 특화된 파라미터 값들만 새로 학습시키는 것이다.
